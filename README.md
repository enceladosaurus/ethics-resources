<div id="top"></div>

<!-- PROJECT SHIELDS -->
<!--
*** I'm using markdown "reference style" links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
-->

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

<h3 align="center">AI Ethics Resources</h3>

  <p align="center">
    A collection of media, content, and additional resources related to AI and technology ethics
  </p>
</div>

<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href="#websites">Websites</a></li>
    <li><a href="#talks">Talks</a></li>
    <li><a href="#podcasts-and-youtube-channels">Podcasts and YouTube Channels</a></li>
    <li><a href="#articles-and-white-papers">Articles and White Papers</a></li>
    <li><a href="#books">Books</a></li>
    <li><a href="#conferences-and-events">Conferences and Events</a></li>
    <li><a href="#published-research">Published Research</a></li>
    <li><a href="#contact">Contact</a></li>
  </ol>
</details>


## Websites

- [AI Ethicist](https://www.aiethicist.org/): a global repository of references and resources related to AI ethics
- [Data & Society](https://datasociety.net/): independent, non-profit research organization studying social implications of data and automation
- [Cyberculture & Social Justice Directory](http://www.cybercultureandsocialjustice.com/): a directory of research in the broader field of cyber ethics
- [Future of Humanity Institute](https://www.fhi.ox.ac.uk/): UK research centre with a subdivisions focused on AI governance and safety
- [AI Ethics Course](https://aiethicscourse.org/): online course in AI ethics
- [Partnership on AI](https://www.partnershiponai.org): non-profit interdisciplinary collaboration focused on positive AI outcomes
- [GRACE: Global Review of AI Community Ethics](https://ojs.stanford.edu/ojs/index.php/grace/about): peer-reviewed journal from Stanford University
- [Interpetable Machine Learning: A Guide for Making Black Box Models Explainable](https://christophm.github.io/interpretable-ml-book/): online book by Christoph Molnar
- [PARC's AI Ethics Committee](https://github.com/PARC/ai-ethics): industry company's AI ethics committee resources
- [DataEthics](https://dataethics.eu/): a non-profit, politically independent organization focused on data ethics
- [Data Ethics Canvas](https://theodi.org/article/the-data-ethics-canvas-2021/): a collection of data ethics resources from the Open Data Institute
- [Center for Human-Compatible Artificial Intelligence](https://humancompatible.ai/): UC Berkeley research group focused on incentivizing beneficial AI
- [Ethics, Technology, and Engineering](https://www.coursera.org/learn/ethics-technology-engineering): Coursera class on technology & engineering ethics
- [UNESCO World Commission on the Ethics of Scientific Knowledge and Technology](https://en.unesco.org/themes/ethics-science-and-technology/comest): UNESCO advisory body
- [AI Now Institute](https://ainowinstitute.org/): New York University research centre devoted to AI accountability
- [Centre for Digital Ethics](https://centri.unibo.it/digital-ethics/it): University of Bologna center focused on digital ethics (website in Italian)
- [Fairness and Machine Learning: Limitations and Opportunties](https://fairmlbook.org/): online textbook 
- [Algorithmic Justice League](https://www.ajl.org/about): organization combining art and research to illuminate social implications and harms of AI
- [Leverhulme Centre for the Future of Intelligence](http://lcfi.ac.uk/): UK-US research collaboration focused on opportunities and challenges of AI
- [The Institute for Ethical AI and Machine Learning](https://ethical.institute/): UK-based research centre focused on responsible development and deployment of AI
- [AddAI](https://www.addai.org/): Sweden-based interdisciplinary collaboration exploring the impact of AI on society
- [Stop Killer Robots](https://www.stopkillerrobots.org/): global coalition focused on regulating autonomy in weapons systems
- [Ethics and Governance of AI](https://cyber.harvard.edu/topics/ethics-and-governance-ai): Harvard's Berkman Klein Center group researching ethics and governance of AI
- [AI Ethics Lab](https://aiethicslab.com/): consulting and research organization focused on AI ethics
- [Ethics of AI](https://ethics-of-ai.mooc.fi/): MOOC by the University of Helsinki
- [European Network of Human-Centered Artificial Intelligence](https://www.humane-ai.eu/): EU funded organization for ethical AI
- [FARI: AI Institute for the Common Good](https://fari.brussels/): Brussels-based, not-for-profit academic collaboration


<p align="right">(<a href="#top">back to top</a>)</p>

## Talks

- [Hierarchy of Knowledge in ML & Related Fields and its Consequences](https://www.youtube.com/watch?v=OL3DowBM9uc): Timnit Gebru
- [Understanding the Limits of AI: When Algorithms Fail](https://www.youtube.com/watch?v=QqZVx6NCkPg): Timnit Gebru
- [From Ethics to Organizing: Getting Serious About AI](https://www.youtube.com/watch?v=_BzU0bD0Ics): Meredith Whittaker 
- [Talking about AI Ethics: Democracy, Privacy, and Work](https://www.youtube.com/watch?v=6m19a84ym94): Panel
- [AI, Hate Speech, and Online Content Moderation Seminar Series](https://aiethicscourse.org/webinars/ai-hate-speech-and-online-content-moderation-seminar-series): various speakers
- [Ethics in the age of technology](https://www.youtube.com/watch?v=iiAirfn-lBI): Juan Enriquez (TEDxBerlin)
- [Digital Ethics and Fintech](https://www.icaew.com/technical/technology/technology-and-the-profession/new-technologies-ethics-and-accountability): Luciano Floridi
- [Prototyping AI ethics futures: rights, access, and refusal](https://www.youtube.com/watch?v=kwq4YaLCubk): Panel
- [Prototyping AI ethics futures: ethics in practice](https://www.youtube.com/watch?v=-4nDFLaJ6gQ): Panel
- [AI ethics online: What fiction can teach us about AI Ethics](https://www.youtube.com/watch?v=fqV7482HubM): Kathryn Strong Hansen
- [Ethical Implications of AI](https://www.youtube.com/watch?v=U_d0SBc6cbs): Francesca Rossi
- [The Dreams our Stuff is Made of: Trust, Agency, and Super-agency](https://www.youtube.com/watch?v=qQjSU9y-NmI): Beth Singler
- [AI, Ethics, and Society: A Primer](https://www.youtube.com/watch?v=DBXZ3oEF6Yc): Daniel Bashir
- [AI Ethics for Enterprise AI](https://www.youtube.com/watch?v=9YrQLSAyNs0): Francesca Rossi
- [How to develop and use AI responsibly](https://www.youtube.com/watch?v=eHWSQo1hqTI): Virginia Dignum


## Podcasts, YouTube Channels, & Documentaries

- [Ethics in AI Podcast](https://podcasts.ox.ac.uk/series/ethics-ai)
- [The Machine Ethics Podcast](https://www.machine-ethics.net/)
- [Markkula Center for Applied Ethics](https://www.youtube.com/channel/UCkdJFnahsmZyRLLTYeSky9w)
- [Ethics in Open Source Podcast](https://anchor.fm/ethicsinopensource)
- [In AI We Trust? Podcast](https://podcasts.apple.com/us/podcast/in-ai-we-trust/id1563248151)
- [DigEthix: Technology and Ethics in Society Podcast](https://podcasts.apple.com/us/podcast/digethix-technology-and-ethics-in-society/id1569434480)
- [The husITa Podcast](https://podcasts.apple.com/us/podcast/the-husita-podcast/id1554594332)
- [The Technically Human Podcast](https://www.etcalpoly.org/the-technically-human-podcast)
- [Artificial intelligence and its ethics](https://www.youtube.com/watch?v=Izd2qOgOGQI)
- [Coded Bias](https://www.imdb.com/title/tt11394170/)
- [Bias in AI: Teaching machines to think responsibly](https://lens.monash.edu/@what-happens-next/2021/09/10/1383751/whnpodcast-bias-in-ai-s5-part2)
- [The Fight for "Ethical AI" and the Hidden Laborers Behind Artificial Intelligence](https://www.kqed.org/forum/2010101891105/the-fight-for-ethical-ai-and-the-hidden-laborers-behind-artificial-intelligence)



<p align="right">(<a href="#top">back to top</a>)</p>

## Articles and White Papers

- AI4People's [Ethical Framework for A Good AI Society: Opportunities, Risks, Principles, and Recommendations](https://www.eismd.eu/wp-content/uploads/2019/02/Ethical-Framework-for-a-Good-AI-Society.pdf)
- [A Practical Guide to Building Ethical AI](https://hbr.org/2020/10/a-practical-guide-to-building-ethical-ai) by Reid Blackman
- [The ethics of artificial intelligence: Issues and initiatives](https://www.europarl.europa.eu/RegData/etudes/STUD/2020/634452/EPRS_STU(2020)634452_EN.pdf)
- [Artificial Intelligence: examples of ethical dilemmas](https://en.unesco.org/artificial-intelligence/ethics/cases)
- [Ethics Owners: A New Model of Organizational Responsibility in Data-Driven Technology Companies](https://datasociety.net/wp-content/uploads/2020/09/Ethics-Owners_20200923-DataSociety.pdf)
- [Artificial Intelligene and Ethics: 16 Challenges and Opportunities](https://www.scu.edu/ethics/all-about-ethics/artificial-intelligence-and-ethics-sixteen-challenges-and-opportunities/)
- [Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems](https://standards.ieee.org/industry-connections/ec/ead-v1/)
- [Ethics Guidelines for Trustworthy AI](https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf)
- [Against Black Inclusion in Facial Recognition](https://digitaltalkingdrum.com/2017/08/15/against-black-inclusion-in-facial-recognition/)
- [Artificial Intelligence in Christian Thought and Practice](https://medium.com/ai-and-christianity/artificial-intelligence-in-christian-thought-and-practice-20ec8635a94f)
- [Algorithms Need Managers, Too](https://hbr.org/2016/01/algorithms-need-managers-too)
- [Physiognomy's New Clothes](https://medium.com/@blaisea/physiognomys-new-clothes-f2d4b59fdd6a)
- [How big data is unfair](http://www.cs.yale.edu/homes/jf/HardtHowBigDataIsUnfair.pdf)
- [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
- [Is Artificial Intelligence Permanently Inscrutable?](https://nautil.us/is-artificial-intelligence-permanently-inscrutable-5116/)
- [Ideas on interpreting machine learning](https://www.oreilly.com/radar/ideas-on-interpreting-machine-learning/)
- [How Companies Learn Your Secrets](https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html)
- [Engineering the public: Big data, surveillance, and computational politics](https://firstmonday.org/article/view/4901/4097)
- [The AI Now Report: The Social and Economic Implications of AI Technologies in the Near-Term](https://ainowinstitute.org/AI_Now_2016_Report.pdf)
- [Algorithms aren't racist. Your skin is just too dark](https://medium.com/hackernoon/algorithms-arent-racist-your-skin-is-just-too-dark-4ed31a7304b8)
- [The Perpetual Line-up: Unregulated Police Face Recognition in America](https://www.perpetuallineup.org/)
- [The Hidden Biases in Big Data](https://hbr.org/2013/04/the-hidden-biases-in-big-data)
- [The Moral Gray Space of AI Decisions](https://ai.shorensteincenter.org/ideas/2018/12/1/the-moral-gray-space-of-ai-decisions-6sc59)
- [Unfairness by Algorithm: Distilling the Harms of Automated Decision Making](https://fpf.org/blog/unfairness-by-algorithm-distilling-the-harms-of-automated-decision-making/)
- [AI Safety Needs Social Scientists](https://distill.pub/2019/safety-needs-social-scientists/)
- Machine Intelligence Research Institute's [Artificial Intelligence as a Positive and Negative Factor in Global Risk](https://intelligence.org/files/AIPosNegFactor.pdf)
- Machine Intelligence Research Institute's [The Ethics of Artificial Intelligence](https://intelligence.org/files/EthicsofAI.pdf)
- Future of Humanity Institute's [AI Governance: A Research Agenda](https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf)
- [The ART of AI - Accountability, Responsibility, and Transparency](https://medium.com/@virginiadignum/the-art-of-ai-accountability-responsibility-transparency-48666ec92ea5)
- [AI or More? A Risk-based Approach to a Technology-based Society](https://www.law.ox.ac.uk/business-law-blog/blog/2021/09/ai-or-more-risk-based-approach-technology-based-society)
- The European Parliament's [Artificial Intelligence: From ethics to policy](https://www.europarl.europa.eu/RegData/etudes/STUD/2020/641507/EPRS_STU(2020)641507_EN.pdf)
- The Centre for Information Policy Leadership's [Hard Issues and Practical Solutions](https://www.huntonprivacyblog.com/wp-content/uploads/sites/28/2020/03/cipl_second_report_-_artificial_intelligence_and_data_protection_-_hard_issues_and_practical_solutions__27_february_2020_1.pdf)
- [6 types of AI bias everyone should know](https://www.seldon.io/6-types-of-ai-bias)
- [ML bias: guidelines to make ML models ethical and reduce risks of discrimination](https://medium.com/glovo-engineering/ml-bias-guidelines-to-make-ml-models-ethical-and-reduce-risks-of-discrimination-1c7165f74210)
- [A People's Guide to Finding Algorithmic Bias](https://www.criticalracedigitalstudies.com/peoplesguide)
- [Governing data and artificial intelligence for all: Models for sustainable and just data governance](https://www.europarl.europa.eu/stoa/en/document/EPRS_STU(2022)729533)
- National Institute of Standards and Technology (NIST)'s [AI Risk Management Framework: Second Draft](https://www.nist.gov/system/files/documents/2022/08/18/AI_RMF_2nd_draft.pdf)

<p align="right">(<a href="#top">back to top</a>)</p>

## Books

- [The Oxford Handbook of Ethics of AI](https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780190067397.001.0001/oxfordhb-9780190067397)
- [Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way](https://philpapers.org/rec/DIGRAI) by Virginia Dignum
- [The Ethical Algorithm: The Science of Socially Aware Algorithm Design](https://www.adlibris.com/se/bok/the-ethical-algorithm-9780190948207?gclid=Cj0KCQiA_8OPBhDtARIsAKQu0gbcVOhkNH_tjphsNP5wm1KznTWXHDkCJJIlri3aHXaAfEey8rGFyxgaAjPFEALw_wcB) by Michael Kearns
- [Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy](https://www.adlibris.com/se/bok/weapons-of-math-destruction-9780141985411?gclid=Cj0KCQiA_8OPBhDtARIsAKQu0gYiPDTv9HX_sDhumMngHt7JBssR02P_TyPSrEaufGyNFn7VOHV8eKEaAgOKEALw_wcB) by Cathy O'Neil
- [Hello World: Being Human in the Age of Algorithms](https://www.adlibris.com/se/bok/hello-world-9781784163068?gclid=Cj0KCQiA_8OPBhDtARIsAKQu0gZyQO-UQTMFtg77hbTcgIIlaU7WPDeuBVAYfks0NoTTHdb6BJKeTAsaAv_3EALw_wcB) by Hannah Fry
- [Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor](https://www.adlibris.com/se/bok/automating-inequality-how-high-tech-tools-profile-police-and-punish-the-poor-9781250215789) by Virginia Eubanks
- [Artificial Unintelligence: How Computers Misunderstand the World](https://mitpress.mit.edu/books/artificial-unintelligence) by Meredith Broussard
- [Algorithms of Oppression: How Search Engines Reinforce Racism](https://nyupress.org/9781479837243/algorithms-of-oppression/) by Safiya Umoja Noble
- [Race After Technology: Abolitionist Tools for the New Jim Code](https://www.adlibris.com/se/bok/race-after-technology-9781509526406?gclid=Cj0KCQiA_8OPBhDtARIsAKQu0gZPHPHgrM_z8cxNWYd1iweWrN21s2NhYVr_8UlRF0xF2prNyOjgugEaAgLaEALw_wcB) by Ruha Benjamin
- [Technically Wrong: Sexist Apps, Biased Algorithms, and Other Threats of Toxic Tech](https://www.adlibris.com/se/bok/technically-wrong-9780393356045?gclid=Cj0KCQiA_8OPBhDtARIsAKQu0gbNvurfR3q9w33ydP9E8eQVLDJ8L84BHnAiPZOoEWHBvzxsRGZrkVQaAgt2EALw_wcB) by Sara Wachter-Boettcher
- [Data Ethics of Power: A Human Approach in the Big Data and AI Era](https://www.e-elgar.com/shop/gbp/data-ethics-of-power-9781802203103.html) by Gry Hasselbalch
- [The Black Box Society](https://www.adlibris.com/se/bok/the-black-box-society-9780674970847?gclid=Cj0KCQiAjJOQBhCkARIsAEKMtO0nwRRi45GVpRDo-zLZeWg3tfZd-a67LpjY7lCRxs_ztRDppqlhp3MaAkTcEALw_wcB) by Frank Pasquale
- [On Being a Data Skeptic](https://www.oreilly.com/library/view/on-being-a/9781491947227/index.html) by Cathy O'Neil
- [Profiles, Probabilities, and Stereotypes](https://www.hup.harvard.edu/catalog.php?isbn=9780674021181) by Frederick Schauer
- [Privacy, Due Process, and the Computational Turn](https://www.bokus.com/bok/9780415644815/privacy-due-process-and-the-computational-turn/) edited by Mireille Hildebrandt and Katja de Vries
- [The GDPR Challenge: Privacy, Technology, and Compliance in an Age of Accelerating Change](https://www.routledge.com/The-GDPR-Challenge-Privacy-Technology-and-Compliance-in-an-Age-of-Accelerating/Taal/p/book/9780367257262) edited by Amie Taal
- [Viral Justice: How We Grow the World We Want](https://press.princeton.edu/books/hardcover/9780691222882/viral-justice) by Ruha Benjamin
- [Design Justice: Community-Led Practices To Build the Worlds We Need](https://mitpress.mit.edu/9780262043458/design-justice/) by Sasha Costanza-Chock
- [Technology and the Virtues](https://global.oup.com/academic/product/technology-and-the-virtues-9780190498511?cc=se&lang=en&) by Shannon Vallor
- [Privacy in Context: Technology, Policy, and the Integrity of Social Life](https://www.sup.org/books/title/?id=8862) by Helen Nissenbaum
- [The Age of Surveillance Capitalism](https://www.publicaffairsbooks.com/titles/shoshana-zuboff/the-age-of-surveillance-capitalism/9781610395694/) by Shoshana Zuboff
- [Privacy is Power: Why And How You Should Take Back Control Of Your Data](https://www.adlibris.com/se/bok/privacy-is-power-9780552177719) by Carissa Véliz
- [Hello World: How to be Human in the Age of the Machine](https://hannahfry.co.uk/book/hello-world/) by Hannah Fry
- [Programmed Inequality: How Britain Discarded Women Technologists and Lost Its Edge in Computing](https://mitpress.mit.edu/9780262535182/programmed-inequality/) by Mar Hicks
- [Behind the Screen: Content Moderation in the Shadows of Social Media](https://yalebooks.yale.edu/book/9780300261479/behind-the-screen/) by Sarah T. Roberts
- [Invisible Women: Exposing Data Bias In A World Designed For Men](https://carolinecriadoperez.com/book/invisible-women/) by Caroline Criado Perez
- [Predict and Surveil: Data, Discretion, And The Future Of Policing](https://global.oup.com/academic/product/predict-and-surveil-9780190684099?cc=se&lang=en&) by Sarah Brayne

<p align="right">(<a href="#top">back to top</a>)</p>

## Conferences and Events

- AAAI/ACM conference on [Artificial Intelligence, Ethics, and Society (AIES)](https://www.aies-conference.com/2022/)
- Re-Work [AI Ethics Summit](https://www.re-work.co/events/ai-ethics-summit-2022)
- ORBIT [Women in AI & Ethics](https://www.orbit-rri.org/conference2019/)
- Artificial Intelligence Applications & Innovations [2nd Workshop on AI and Ethics](https://ifipaiai.org/2022/workshops/?gclid=Cj0KCQiAosmPBhCPARIsAHOen-NvirUKsdonNFoYmc1DtaTfgpOhUZZh51gntpmOAmFJLdQ7UJj_kTAaAttuEALw_wcB#aiethics)
- IEEE [International Symposium on Technology and Society](https://attend.ieee.org/istas-2021/)

<p align="right">(<a href="#top">back to top</a>)</p>

## Published Research

*Note: this is not an exhaustive list by any means and reflects some of my own research interests. Feel free to request additional Key Topics tags!*

| Authors | Title | Year | Key Topics |
| ------- | ----- | ---- | ---------- |
| Ananny & Crawford | [Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability](https://journals.sagepub.com/doi/10.1177/1461444816676645) | 2016 | `Algorithmic Fairness` | 
| Aroyo & Welty | [Truth is a Lie: Crowd Truth and the Seven Myths of Human Annotation](https://ojs.aaai.org/index.php/aimagazine/article/view/2564) | 2015 | `Data` `NLP` |
| Aroyo et al. | [Data Excellence for AI: Why Should You Care](https://arxiv.org/ftp/arxiv/papers/2111/2111.10391.pdf) | 2021 | `Data` |
| Barocas, S. | [Data Mining and the Discourse on Discrimination](https://www.cs.yale.edu/homes/jf/Barocas-Taxonomy.pdf) | 2014 | `Data` |
| Barocas & Nissenbaum | [Big Data's End Run Around Procedural Privacy Protections](https://cacm.acm.org/magazines/2014/11/179832-big-datas-end-run-around-procedural-privacy-protections/fulltext?mobile=false) | 2014 | `Data` `Privacy` `Policy` | 
| Bartl et al. | [Unmasking Contextual Stereotypes: Measuring and Mitigating BERT's Gender Bias](https://arxiv.org/pdf/2010.14534.pdf) | 2020 | `NLP` `LLM` `Bias Mitigation` | 
| Basta et al. | [Evaluating the Underlying Gender Bias in Contextualized Word Embeddings](https://aclanthology.org/W19-3805.pdf) | 2019 | `NLP` `LLM` | 
| Berk et al. | [Fairness in Criminal Justice Risk Assessments: The State of the Art](https://arxiv.org/abs/1703.09207) | 2017 | `Algorithmic Fairness` | 
| Bender et al. | [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](https://dl.acm.org/doi/10.1145/3442188.3445922) | 2021 | `NLP` `LLM` |
| Bertrand & Mullainathan | [Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination](https://www.aeaweb.org/articles?id=10.1257/0002828042002561) | 2004 | `Social Justice` |
| Birhane, A. | [Algorithmic injustice: a relational ethics approach](https://www.cell.com/patterns/fulltext/S2666-3899(21)00015-5?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS2666389921000155%3Fshowall%3Dtrue) | 2021 | `Algorithmic Fairness` `Feminism` |
| Bolukbasi et al. | [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/abs/1607.06520) | 2016 | `NLP` `Bias Mitigation` `LLM` | 
| Brandusescu & Reia | [Artificial Intelligence in the City: Building Civic Engagement and Public Trust](https://libraopen.lib.virginia.edu/public_view/5t34sj769) | 2022 | `Data` `Policy` | 
| Brey et al. | [An ethical framework for the development and use of AI and robotics technologies](https://www.sienna-project.eu/digitalAssets/801/c_801912-l_1-k_d4.7_ethical-framework-for-ai--robotics_v2.pdf) | 2020 | `Guidelines & Recommendations` | 
| Burrell, J. | [How the machine "thinks": Understanding opacity in machine learning algorithms](https://journals.sagepub.com/doi/full/10.1177/2053951715622512) | 2016 | `XAI` | 
| Buolamwini & Gebru | [Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification](https://dam-prod.media.mit.edu/x/2018/02/06/Gender%20Shades%20Intersectional%20Accuracy%20Disparities.pdf) | 2018 | `Computer Vision` `Algorithmic Fairness` `Data` | 
| Caliskan et al. | [Semantics derived automatically form language corpora contain human-like biases](https://arxiv.org/abs/1608.07187) | 2017 | `NLP` | 
| Chen et al. | [Enhancing Transparency and Control When Drawing Data-Driven Inferences About Individuals](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5647518/) | 2017 | `Data` `Privacy`|
| Cho et al. | [DALL-Eval: Probing the Reasoning Skills and Social Biased of Text-to-Image Generative Transformers](https://arxiv.org/abs/2202.04053) | 2022 | `Computer Vision` |
| Citron & Pasquale | [The Scored Society: Due Process for Automated Predictions](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2376209) | 2014 | `Data` | 
| Cooper, J. | [Separation Anxiety](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2655794) | 2017 | `Privacy` `Policy` | 
| Crawford & Schultz | [Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms](https://lawdigitalcommons.bc.edu/bclr/vol55/iss1/4/) | 2014 | `Data` `Privacy` `Policy` | 
| Davis & Osoba | [Privacy Preservation in the Age of Big Data](https://www.rand.org/pubs/working_papers/WR1161.html) | 2016 | `Privacy` `Data` |
| Devinney et al. | [Theories of "Gender" in NLP Bias Research](https://arxiv.org/pdf/2205.02526.pdf) | 2022 | `NLP` `Bias Mitigation` |
| Diakopoulos, N. | [Algorithmic Accountability: Journalistic investigation of computational power structures](https://www.tandfonline.com/doi/abs/10.1080/21670811.2014.976411) | 2014 | `Algorithmic Fairness` |
| Dietvorst et al. | [Algorithm Aversion: People Erroneously Avoid Algorithms After Seeing Them Err](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1392&context=fnce_papers#:~:text=We%20show%20that%20people%20are,them%20make%20the%20same%20mistake.) | 2015 | `Policy`| 
| Dillon, S. | [The Eliza Effect and Its Dangers: From Demystification to Gender Critique](https://www.repository.cam.ac.uk/bitstream/handle/1810/304211/Dillon%20The%20Eliza%20Effect%20JCR.pdf?sequence=1&isAllowed=n) | 2020 | `Virtual Assistants` `Feminism` |
| Doshi-Velez & Kim | [Towards A Rigorous Science of Interpretable Machine Learning](https://arxiv.org/abs/1702.08608) | 2017 | `XAI` | 
| Drosou et al. | [Diversity in Big Data: A Review](https://www.cs.drexel.edu/~julia/documents/big.2016.0054.pdf) | 2017 | `Data` | 
| Du et al. | [VOS: Learning What You Don't Know by Virtual Outlier Synthesis](https://arxiv.org/abs/2202.01197) | 2022 | `XAI`|
| Dwork et al. | [Fairness Through Awareness](https://arxiv.org/abs/1104.3913) | 2011 | `Algorithmic Fairness` | 
| Edwards & Veale | [Slave to the Algorithm? Why a "Right to an Explanation" is Probably Not the Remedy You Are Looking For](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2972855) | 2017 | `XAI` `Algorithmic Fairness` `Policy` | 
| Fazelpour & De-Arteaga | [Diversity in Sociotechnical Machine Learning Systems](https://arxiv.org/pdf/2107.09163.pdf) | 2021 | `Algorithmic Fairness` | 
| Floridi & Cowls | [A Unified Framework of Five Principles for AI in Society](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3831321) | 2021 | `Guidelines & Recommendations` |
| Friedler et al. | [On the (im)possibility of fairness](https://arxiv.org/abs/1609.07236) | 2016 | `Algorithmic Fairness` |
| Gebru et al. | [Datasheets for Datasets](https://arxiv.org/pdf/1803.09010.pdf) | 2021 | `Data` `XAI` |
| Gillespie, T. | [The Relevance of Algorithms](https://www.microsoft.com/en-us/research/wp-content/uploads/2014/01/Gillespie_2014_The-Relevance-of-Algorithms.pdf) | 2014 | `Algorithmic Fairness` `XAI`| 
| Grgić-Hlača et al. | [The Case for Process Fairness in Learning: Feature Selection for Fair Decision Making](https://people.mpi-sws.org/~gummadi/papers/process_fairness.pdf) | 2016 | `Algorithmic Fairness` `Guidelines & Recommendations` |
| Grimmelmann & Westreich | [Incomprehensible Discrimination](https://scholarship.law.cornell.edu/facpub/1536/) | 2017 | `Data` `Algorithmic Fairness` | 
| Gonen & Goldberg | [Lipstick on a Pig: Debiasing Methods Cover up Systemic Gender Biases in Word Embeddings But Do Not Remove Them](https://arxiv.org/pdf/1903.03862.pdf) | 2019 | `NLP` `LLM` |
| Goodman, B. | [Economic Models of (Algorithmic) Discrimination](http://www.mlandthelaw.org/papers/goodman2.pdf) | 2016 | `Algorithmic Fairness` | 
| Guo & Caliskan | [Detecting Emergent Intersectional Biases: Contextualized Word Embeddings Contain a Distribution of Human-like Biases](https://dl.acm.org/doi/pdf/10.1145/3461702.3462536) | 2021 | `NLP` `LLM` |
| Haggerdy, K. | [Methodology as a Knife Fight: The Process, Politics, and Paradox of Evaluating Surveillance](https://link.springer.com/article/10.1007/s10612-009-9083-y) | 2009 | `Policy` `Surveillance` | 
| Hanna et al. | [Towards a Critical Race Methodology in Algorithmic Fairness](https://arxiv.org/pdf/1912.03593.pdf) | 2019 | `Critical Race Theory` `Algorithmic Fairness` |
| Hardt et al. | [Equality of Opportunity in Supervised Learning](https://arxiv.org/pdf/1610.02413.pdf) | 2016 | `Supervised Learning` `Algorithmic Fairness` |
| Helveston, M. | [Consumer Protection in the Age of Big Data](https://openscholarship.wustl.edu/law_lawreview/vol93/iss4/5/) | 2016 | `Data` `Privacy` | 
| Hine & Floridi | [Artificial Intelligence with American Values and Chinese Characteristics: A Comparative Analysis of American and Chinese Governmental AI Policies](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4006332) | 2022 | `Policy` |
| Hutchinson & Mitchell | [50 Years of Test (Un)fairness: Lessons for Machine Learning](http://www.m-mitchell.com/papers/History_of_Fairness-arxiv.pdf) | 2019 | `Algorithmic Fairness` |
| Hutchinson et al. | [Towards Accountability for Machine Learning Datasets: Practices from Sofftware Engineering and Infrastructure](https://arxiv.org/pdf/2010.13561.pdf) | 2021 | `Data` |
| Jacobs & Wallach | [Measurement and Fairness](https://arxiv.org/pdf/1912.05511.pdf) | 2021 | `Algorithmic Fairness` | 
| Jacovi et al. | [Diagnosing AI Explanation Methods with Folk Concepts of Behavior](https://arxiv.org/pdf/2201.11239.pdf) | 2022 | `XAI`|
| Jobin et al. | [The global landscape of AI ethics](https://www.nature.com/articles/s42256-019-0088-2) | 2019 | `Literature Review` |
| Jones, M. | [The right to a human in the loop: Political constructions of computer automation and personhood](https://journals.sagepub.com/doi/abs/10.1177/0306312717699716) | 2017 | `Policy` `Algorithmic Fairness` | 
| Joseph et al. | [Fairness in Learning: Classic and Contextual Bandits](https://papers.nips.cc/paper/2016/hash/eb163727917cbba1eea208541a643e74-Abstract.html) | 2016 | `Algorithmic Fairness` `RL` | 
| Jung et al. | [Simple Rules for Complex Decisions](https://arxiv.org/pdf/1702.04690.pdf)| 2017 | `Guidelines & Suggestions` | 
| Kaptein & Eckles | [Selecting Effective Means to Any End; Futures and Ethics of Persuasion Profiling](https://link.springer.com/chapter/10.1007/978-3-642-13226-1_10) | 2010 | `Policy` |
| Kerr et al. | [Expectations of artificial intelligence and the performativity of ethics: implications for communication governance](https://journals.sagepub.com/doi/full/10.1177/2053951720915939) | 2020 | `Policy` |
| Kleinberg et al. | [Inherent Trade-Offs in the Fair Determination of Risk Scores](https://arxiv.org/abs/1609.05807) | 2016 | `Algorithmic Fairness` |
| Kochelek, D. | [Data Mining and Antitrust](http://jolt.law.harvard.edu/articles/pdf/v22/22HarvJLTech515.pdf) | 2009 | `Data` `Privacy` | 
| Kosinski et al. | [Private traits and attributes are predictable from digital records of human behavior](https://www.pnas.org/content/110/15/5802) | 2013 | `Privacy` `Data` | 
| Kroll et al. | [Accountable Algorithms](https://scholarship.law.upenn.edu/penn_law_review/vol165/iss3/3/) | 2017 | `Algorithmic Fairness` | 
| Kurita et al. | [Measuring Bias in Contextualized Word Representations](https://aclanthology.org/W19-3823.pdf) | 2019 | `NLP` `LLM` |
| Lee, M. | [Understanding Perceptions of Algorithmic Decisions: Fairness, Trust, and Emotion in Response to Algorithmic Management](https://journals.sagepub.com/doi/full/10.1177/2053951718756684) | 2018 | `Algorithmic Fairness` |
| Lippert-Rasmussen, K. | ["We are all Different": Statistical Discrimination and the Right to be Treated as in Individual](https://link.springer.com/article/10.1007/s10892-010-9095-6) | 2010 | `Data` | 
| Lipton, Z. | [The Mythos of Model Interpretability](https://arxiv.org/abs/1606.03490) | 2016 | `XAI` | 
| Liu et al. | [Privacy and Security Issues in Deep Learning: A Survey](https://ieeexplore.ieee.org/document/9294026) | 2021 | `Privacy` | 
| Matthews et al. | [Gender Bias in Natural Language Processing Across Human Languages](https://aclanthology.org/2021.trustnlp-1.6.pdf) | 2021 | `NLP` `LLM` | 
| McGregor, S. | [Preventing Repeated Real World AI Failures by Cataloging Incidents: The AI Incident Database](https://arxiv.org/pdf/2011.08512.pdf) | 2020 | `Datasets`|
| Mehrabi et al. | [A Survey on Bias and Fairness in Machine Learning](https://arxiv.org/pdf/1908.09635.pdf) | 2022 | `Algorithmic Fairness`
| Miceli et al. | [Documenting Data Production Processes: A Participatory Approach for Data Work](https://arxiv.org/pdf/2207.04958.pdf) | 2022 | `Data` `Guidelines & Recommendations` | 
| Mitchell et al. | [Model Cards for Model Reporting](https://arxiv.org/pdf/1810.03993.pdf) | 2019 | `Data` `XAI` | 
| Nadeem et al. | [StereoSet: Measuring stereotypical bias in pretrained language models](https://arxiv.org/pdf/2004.09456.pdf) | 2020 | `NLP` `LLM` `Datasets` |
| Nangia et al. | [CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models](https://arxiv.org/pdf/2010.00133.pdf) | 2020 | `NLP` `LLM` `Datasets` |
| Prabhakaran et al. | [A Human Rights-Based Approach to Responsible AI](https://arxiv.org/abs/2210.02667) | 2022 | `Algorithmic Fairness` `Guidelines & Recommendations` | 
| Prabhu & Birhane | [Large Datasets: A Pyrrhic Win for Computer Vision?](https://arxiv.org/pdf/2006.16923.pdf) | 2020 | `Computer Vision` `Data` | 
| Raji & Buolamwini | [Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products](https://dam-prod.media.mit.edu/x/2019/01/24/AIES-19_paper_223.pdf) | 2019 | `Algorithmic Fairness` |
| Ryan & Stahl | [Artificial intelligence ethics guidelines for developers and users: clarifying their content and normative implications](https://www.researchgate.net/publication/342080262_Artificial_intelligence_ethics_guidelines_for_developers_and_users_clarifying_their_content_and_normative_implications) | 2020 | `Guidelines & Recommendations` | 
| Sandvig et al. | [Auditing Algorithms: Research Methods for Detecting Discrimination on Internet Platforms](http://www-personal.umich.edu/~csandvig/research/Auditing%20Algorithms%20--%20Sandvig%20--%20ICA%202014%20Data%20and%20Discrimination%20Preconference.pdf) | 2014 | `Algorithmic Fairness` `Guidelines & Suggestions` |
| Selbst et al. | [Fairness and Abstraction in Sociotechnical Systems](https://dl.acm.org/doi/10.1145/3287560.3287598) | 2019 | `Algorithmic Fairness` |
| Sloane et al. | [Participation is not a Design Fix for Machine Learning](https://arxiv.org/ftp/arxiv/papers/2007/2007.02423.pdf) | 2020 | `Guidelines & Recommendations` |
| Suresh et al. | [A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle](https://arxiv.org/pdf/1901.10002.pdf) | 2021 | `Algorithmic Fairness` |
| Swedloff, R. | [Risk Classification's Big Data (R)evolution](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2566594) | 2014 | `Data` `Algorithmic Fairness` | 
| Taddeo & Floridi | [How AI can be a force for good](https://science.sciencemag.org/content/361/6404/751) | 2018 | `Guidelines & Recommendations` |
| Tene & Polonetsky | [Taming the Golem: Challenges of Ethical Algorithmic Decision Making](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2981466) | 2017 | `Algorithmic Fairness` |
| Thylstrup, N. | [The ethics and politics of data sets in the age of machine learning: deleting traces and encountering remains](https://journals.sagepub.com/doi/abs/10.1177/01634437211060226?journalCode=mcsa) | 2022 | `Data` `Privacy` |
| Tsamados et al. | [The ethics of algorithms: key problems and solutions](https://link.springer.com/article/10.1007/s00146-021-01154-8) | 2021 | `Algorithmic Fairness`|
| Vakkuri et al. | [AI Ethics in Industry: A Research Framework](https://jyx.jyu.fi/handle/123456789/67326) | 2019 | `Guidelines & Suggestions` `XAI` | 
| Webster et al. | [Measuring and Reducing Gendered Correlations in Pre-trained Models](https://arxiv.org/pdf/2010.06032.pdf) | 2020 | `NLP` `Bias Mitigation` `LLM` |
| Wu & Zhang | [Responses to Critiques on Machine Learning of Criminality Perceptions](https://arxiv.org/pdf/1611.04135.pdf) | 2017 | `Algorithmic Fairness` `Computer Vision` | 
| Zarsky, T. | [The Trouble with Algorithmic Decisions: An Analytic Road Map to Examine Efficiency and Fairness in Automated and Opaque Decision Making](https://journals.sagepub.com/doi/abs/10.1177/0162243915605575) | 2015 | `Privacy` `XAI` |
| Zarsky, T. | [Transparent Predictions](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2324240) | 2013 | `Data` `Privacy` `Policy` | 
| Zhang & Zhao | [Online Decision Trees with Fairness](https://arxiv.org/pdf/2010.08146.pdf) | 2020 | `Algorithmic Fairness` | 
| Zhang et al. | [Mitigating Unwanted Biases with Adversarial Learning](http://www.m-mitchell.com/papers/Adversarial_Bias_Mitigation.pdf) | 2018 | `Bias Mitigation` |
| Zhao et al. | [Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints](https://aclanthology.org/D17-1323/) | 2017 | `NLP` `Bias Mitigation` | 
<p align="right">(<a href="#top">back to top</a>)</p>

## Contact

Jesse Shanahan - [@enceladosaurus](https://twitter.com/enceladosaurus) - jess.c.shanahan@gmail.com

<p align="right">(<a href="#top">back to top</a>)</p>


<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[contributors-shield]: https://img.shields.io/github/contributors/enceladosaurus/ethics-resources.svg?style=for-the-badge
[contributors-url]: https://github.com/enceladosaurus/ethics-resources/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/enceladosaurus/ethics-resources.svg?style=for-the-badge
[forks-url]: https://github.com/enceladosaurus/ethics-resources/network/members
[stars-shield]: https://img.shields.io/github/stars/enceladosaurus/ethics-resources.svg?style=for-the-badge
[stars-url]: https://github.com/enceladosaurus/ethics-resources/stargazers
[issues-shield]: https://img.shields.io/github/issues/enceladosaurus/ethics-resources.svg?style=for-the-badge
[issues-url]: https://github.com/enceladosaurus/ethics-resources/issues
